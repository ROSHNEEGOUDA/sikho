{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad909cf8-85f8-4701-883d-ac5ca4c232bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\roshnee\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorflow) (6.32.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\roshnee\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\roshnee\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorflow) (1.75.1)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\roshnee\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\roshnee\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\roshnee\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\roshnee\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (10.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\roshnee\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\roshnee\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\roshnee\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63e54352-3e9b-4a8c-942f-2d5680873c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created by: रोशनी गौड़\n"
     ]
    }
   ],
   "source": [
    "print(\"created by: \\u0930\\u094b\\u0936\\u0928\\u0940 \\u0917\\u094c\\u095c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a740941-bba3-414d-b907-3e8499749f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.utils import to_categorical, pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Lambda\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f7ee80b-b422-4765-bfae-8e1e4b38b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"Natural Language Processing is a field of Artificial Intelligence.\",\n",
    "    \"Word embeddings help computers understand human language.\",\n",
    "    \"The CBOW model is a part of Word2Vec technique.\",\n",
    "    \"CBOW predicts the target word using surrounding context words.\",\n",
    "    \"Skip Gram is another architecture of Word2Vec.\",\n",
    "    \"Word2Vec is widely used in NLP applications.\",\n",
    "    \"Embedding layers in deep learning are used to represent words.\",\n",
    "    \"CBOW is faster and works better with frequent words.\"\n",
    "]\n",
    "#A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75d6e96e-a852-427f-9bca-8631476d458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 41\n",
      "Sample Vocabulary: [('cbow', 1), ('word2vec', 2), ('words', 3), ('language', 4), ('word', 5), ('used', 6), ('natural', 7), ('processing', 8), ('field', 9), ('artificial', 10)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Roshnee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "tokenizer = text.Tokenizer()\n",
    "tokenizer.fit_on_texts([[w for w in text.text_to_word_sequence(doc) if w not in stop_words] for doc in data])\n",
    "\n",
    "word2id = tokenizer.word_index\n",
    "word2id['PAD'] = 0 \n",
    "id2word = {v: k for k, v in word2id.items()}\n",
    "\n",
    "wids = [[word2id.get(w, word2id['PAD']) for w in text.text_to_word_sequence(doc) if w not in stop_words]for doc in data] #id to words\n",
    "\n",
    "vocab_size = len(word2id)\n",
    "embed_size = 100\n",
    "window_size = 2 \n",
    "\n",
    "print(\"Vocabulary Size:\", vocab_size)\n",
    "print(\"Sample Vocabulary:\", list(word2id.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbdbdeeb-2120-49d6-b890-e4f4991d7b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_word_pairs(corpus, window_size, vocab_size):\n",
    "    context_length = window_size * 2\n",
    "    for words in corpus:\n",
    "        sentence_length = len(words)\n",
    "        for index, word in enumerate(words):\n",
    "            context_words = []\n",
    "            label_word = []            \n",
    "            start = index - window_size\n",
    "            end = index + window_size + 1\n",
    "            \n",
    "            context_words.append([words[i] \n",
    "                                  for i in range(start, end) \n",
    "                                  if 0 <= i < sentence_length and i != index])\n",
    "            label_word.append(word)\n",
    "\n",
    "            x = pad_sequences(context_words, maxlen=context_length)\n",
    "            y = to_categorical(label_word, vocab_size) # 1 hot encoded centre word\n",
    "            yield (x, y)\n",
    "        #B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "058416f6-30e7-4edb-8a54-bd11cd3fd201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context (X): ['natural', 'language', 'field', 'artificial'] -> Target (Y): processing\n",
      "Context (X): ['language', 'processing', 'artificial', 'intelligence'] -> Target (Y): field\n",
      "Context (X): ['word', 'embeddings', 'computers', 'understand'] -> Target (Y): help\n",
      "Context (X): ['embeddings', 'help', 'understand', 'human'] -> Target (Y): computers\n",
      "Context (X): ['help', 'computers', 'human', 'language'] -> Target (Y): understand\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for x, y in generate_context_word_pairs(wids, window_size, vocab_size):\n",
    "    if 0 not in x[0]:  # skip padded ones\n",
    "        print(\"Context (X):\", [id2word[w] for w in x[0]], \"-> Target (Y):\", id2word[np.argmax(y[0])])\n",
    "        i += 1\n",
    "        if i == 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3430dfec-3405-48cd-91fd-2ce1cf4aba4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshnee\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:100: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,141</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │           \u001b[38;5;34m4,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m)                  │           \u001b[38;5;34m4,141\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,241</span> (32.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,241\u001b[0m (32.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,241</span> (32.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,241\u001b[0m (32.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "cbow = Sequential()\n",
    "cbow.add(Embedding(input_dim=vocab_size, output_dim=embed_size, input_shape=(window_size*2,)))\n",
    "cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(embed_size,)))\n",
    "cbow.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "cbow.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "#C\n",
    "print(cbow.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9f0dcea-58cf-4f5d-952f-b3c0f620f527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tLoss: 181.98066759109497\n",
      "\n",
      "Epoch: 2 \tLoss: 181.45550847053528\n",
      "\n",
      "Epoch: 3 \tLoss: 180.33871245384216\n",
      "\n",
      "Epoch: 4 \tLoss: 179.12486481666565\n",
      "\n",
      "Epoch: 5 \tLoss: 177.76869773864746\n",
      "\n",
      "Epoch: 6 \tLoss: 176.23424887657166\n",
      "\n",
      "Epoch: 7 \tLoss: 174.49693965911865\n",
      "\n",
      "Epoch: 8 \tLoss: 172.54545974731445\n",
      "\n",
      "Epoch: 9 \tLoss: 170.38276362419128\n",
      "\n",
      "Epoch: 10 \tLoss: 168.02441811561584\n",
      "\n",
      "Epoch: 11 \tLoss: 165.49482226371765\n",
      "\n",
      "Epoch: 12 \tLoss: 162.821932554245\n",
      "\n",
      "Epoch: 13 \tLoss: 160.03305459022522\n",
      "\n",
      "Epoch: 14 \tLoss: 157.15254831314087\n",
      "\n",
      "Epoch: 15 \tLoss: 154.2017364501953\n",
      "\n",
      "Epoch: 16 \tLoss: 151.199720621109\n",
      "\n",
      "Epoch: 17 \tLoss: 148.16437792778015\n",
      "\n",
      "Epoch: 18 \tLoss: 145.1125738620758\n",
      "\n",
      "Epoch: 19 \tLoss: 142.06028652191162\n",
      "\n",
      "Epoch: 20 \tLoss: 139.02212023735046\n",
      "\n",
      "Epoch: 21 \tLoss: 136.01116108894348\n",
      "\n",
      "Epoch: 22 \tLoss: 133.03862261772156\n",
      "\n",
      "Epoch: 23 \tLoss: 130.11375546455383\n",
      "\n",
      "Epoch: 24 \tLoss: 127.24388909339905\n",
      "\n",
      "Epoch: 25 \tLoss: 124.4348042011261\n",
      "\n",
      "Epoch: 26 \tLoss: 121.69065451622009\n",
      "\n",
      "Epoch: 27 \tLoss: 119.01434564590454\n",
      "\n",
      "Epoch: 28 \tLoss: 116.40778541564941\n",
      "\n",
      "Epoch: 29 \tLoss: 113.87210440635681\n",
      "\n",
      "Epoch: 30 \tLoss: 111.40774178504944\n",
      "\n",
      "Epoch: 31 \tLoss: 109.014564037323\n",
      "\n",
      "Epoch: 32 \tLoss: 106.69208931922913\n",
      "\n",
      "Epoch: 33 \tLoss: 104.43946146965027\n",
      "\n",
      "Epoch: 34 \tLoss: 102.25558423995972\n",
      "\n",
      "Epoch: 35 \tLoss: 100.13918089866638\n",
      "\n",
      "Epoch: 36 \tLoss: 98.08875548839569\n",
      "\n",
      "Epoch: 37 \tLoss: 96.10268819332123\n",
      "\n",
      "Epoch: 38 \tLoss: 94.1792985200882\n",
      "\n",
      "Epoch: 39 \tLoss: 92.31680202484131\n",
      "\n",
      "Epoch: 40 \tLoss: 90.51337397098541\n",
      "\n",
      "Epoch: 41 \tLoss: 88.76715314388275\n",
      "\n",
      "Epoch: 42 \tLoss: 87.07625496387482\n",
      "\n",
      "Epoch: 43 \tLoss: 85.4388655424118\n",
      "\n",
      "Epoch: 44 \tLoss: 83.85310864448547\n",
      "\n",
      "Epoch: 45 \tLoss: 82.31716597080231\n",
      "\n",
      "Epoch: 46 \tLoss: 80.82924664020538\n",
      "\n",
      "Epoch: 47 \tLoss: 79.38759648799896\n",
      "\n",
      "Epoch: 48 \tLoss: 77.99049389362335\n",
      "\n",
      "Epoch: 49 \tLoss: 76.63626968860626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''X, Y = [], []\n",
    "for x, y in generate_context_word_pairs(wids, window_size, vocab_size):\n",
    "    X.append(x[0])  # 1 d array\n",
    "    Y.append(y[0])  \n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "print(\"Training Data Shape:\", X.shape, Y.shape)\n",
    "\n",
    "history = cbow.fit(\n",
    "    X, Y,\n",
    "    epochs=10,\n",
    "    batch_size=32, #(32+17)\n",
    "    verbose=0\n",
    ")'''\n",
    "\n",
    "for epoch in range(1, 50):\n",
    "    loss = 0.\n",
    "    i = 0\n",
    "    for x, y in generate_context_word_pairs(corpus=wids, window_size=window_size, vocab_size=vocab_size):\n",
    "        i += 1\n",
    "        loss += cbow.train_on_batch(x, y)\n",
    "        if i % 100000 == 0:\n",
    "            print('Processed {} (context, word) pairs'.format(i))\n",
    "\n",
    "    print('Epoch:', epoch, '\\tLoss:', loss)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36856118-7f22-4b40-bb21-2ec6768ac867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word2vec</th>\n",
       "      <td>0.352018</td>\n",
       "      <td>-0.434074</td>\n",
       "      <td>-0.104973</td>\n",
       "      <td>0.173810</td>\n",
       "      <td>-0.383382</td>\n",
       "      <td>-0.055270</td>\n",
       "      <td>0.417691</td>\n",
       "      <td>0.222921</td>\n",
       "      <td>0.227587</td>\n",
       "      <td>0.309437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378679</td>\n",
       "      <td>0.728197</td>\n",
       "      <td>0.035561</td>\n",
       "      <td>0.441801</td>\n",
       "      <td>0.360132</td>\n",
       "      <td>-0.184294</td>\n",
       "      <td>-0.204133</td>\n",
       "      <td>-0.011996</td>\n",
       "      <td>0.606085</td>\n",
       "      <td>-0.333869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>-0.284951</td>\n",
       "      <td>-0.309418</td>\n",
       "      <td>0.624363</td>\n",
       "      <td>-0.489778</td>\n",
       "      <td>0.084887</td>\n",
       "      <td>0.361340</td>\n",
       "      <td>0.233101</td>\n",
       "      <td>-0.544445</td>\n",
       "      <td>0.542537</td>\n",
       "      <td>0.731797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074275</td>\n",
       "      <td>0.490322</td>\n",
       "      <td>0.472407</td>\n",
       "      <td>0.066562</td>\n",
       "      <td>0.689298</td>\n",
       "      <td>-0.280289</td>\n",
       "      <td>-0.207738</td>\n",
       "      <td>0.344961</td>\n",
       "      <td>0.551165</td>\n",
       "      <td>-0.409315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>-0.513743</td>\n",
       "      <td>-0.008611</td>\n",
       "      <td>0.108116</td>\n",
       "      <td>-0.017404</td>\n",
       "      <td>0.256702</td>\n",
       "      <td>0.065605</td>\n",
       "      <td>-0.117492</td>\n",
       "      <td>-0.654128</td>\n",
       "      <td>-0.597783</td>\n",
       "      <td>0.551359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016540</td>\n",
       "      <td>-0.713183</td>\n",
       "      <td>-0.283292</td>\n",
       "      <td>0.341617</td>\n",
       "      <td>0.216707</td>\n",
       "      <td>0.151271</td>\n",
       "      <td>0.522702</td>\n",
       "      <td>0.130717</td>\n",
       "      <td>-0.001808</td>\n",
       "      <td>-0.445739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>0.169356</td>\n",
       "      <td>0.507206</td>\n",
       "      <td>0.210628</td>\n",
       "      <td>0.504095</td>\n",
       "      <td>0.108347</td>\n",
       "      <td>-0.281278</td>\n",
       "      <td>0.218709</td>\n",
       "      <td>0.207728</td>\n",
       "      <td>0.324459</td>\n",
       "      <td>0.191649</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197952</td>\n",
       "      <td>0.154228</td>\n",
       "      <td>0.475912</td>\n",
       "      <td>0.548594</td>\n",
       "      <td>0.124993</td>\n",
       "      <td>0.482804</td>\n",
       "      <td>0.092264</td>\n",
       "      <td>-0.621354</td>\n",
       "      <td>0.213806</td>\n",
       "      <td>-0.184896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>used</th>\n",
       "      <td>-0.006296</td>\n",
       "      <td>-0.305421</td>\n",
       "      <td>0.142024</td>\n",
       "      <td>0.237366</td>\n",
       "      <td>-0.331905</td>\n",
       "      <td>0.587903</td>\n",
       "      <td>-0.533791</td>\n",
       "      <td>0.482473</td>\n",
       "      <td>0.168174</td>\n",
       "      <td>-0.133638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405431</td>\n",
       "      <td>0.514301</td>\n",
       "      <td>-0.366554</td>\n",
       "      <td>0.285204</td>\n",
       "      <td>-0.459063</td>\n",
       "      <td>0.692945</td>\n",
       "      <td>-0.090628</td>\n",
       "      <td>-0.177005</td>\n",
       "      <td>0.462135</td>\n",
       "      <td>0.433044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5   \\\n",
       "word2vec  0.352018 -0.434074 -0.104973  0.173810 -0.383382 -0.055270   \n",
       "words    -0.284951 -0.309418  0.624363 -0.489778  0.084887  0.361340   \n",
       "language -0.513743 -0.008611  0.108116 -0.017404  0.256702  0.065605   \n",
       "word      0.169356  0.507206  0.210628  0.504095  0.108347 -0.281278   \n",
       "used     -0.006296 -0.305421  0.142024  0.237366 -0.331905  0.587903   \n",
       "\n",
       "                6         7         8         9   ...        90        91  \\\n",
       "word2vec  0.417691  0.222921  0.227587  0.309437  ...  0.378679  0.728197   \n",
       "words     0.233101 -0.544445  0.542537  0.731797  ...  0.074275  0.490322   \n",
       "language -0.117492 -0.654128 -0.597783  0.551359  ...  0.016540 -0.713183   \n",
       "word      0.218709  0.207728  0.324459  0.191649  ... -0.197952  0.154228   \n",
       "used     -0.533791  0.482473  0.168174 -0.133638  ...  0.405431  0.514301   \n",
       "\n",
       "                92        93        94        95        96        97  \\\n",
       "word2vec  0.035561  0.441801  0.360132 -0.184294 -0.204133 -0.011996   \n",
       "words     0.472407  0.066562  0.689298 -0.280289 -0.207738  0.344961   \n",
       "language -0.283292  0.341617  0.216707  0.151271  0.522702  0.130717   \n",
       "word      0.475912  0.548594  0.124993  0.482804  0.092264 -0.621354   \n",
       "used     -0.366554  0.285204 -0.459063  0.692945 -0.090628 -0.177005   \n",
       "\n",
       "                98        99  \n",
       "word2vec  0.606085 -0.333869  \n",
       "words     0.551165 -0.409315  \n",
       "language -0.001808 -0.445739  \n",
       "word      0.213806 -0.184896  \n",
       "used      0.462135  0.433044  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = cbow.get_weights()[0]\n",
    "weights = weights[1:] #1st row\n",
    "print(weights.shape)\n",
    "\n",
    "pd.DataFrame(weights, index=list(id2word.values())[1:]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1a2d6f0-ef51-437b-af57-16381495c69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a word to find similar words:  deep\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top similar words to 'deep': ['layers', 'learning', 'represent', 'embedding', 'applications']\n"
     ]
    }
   ],
   "source": [
    "user_word = input(\"Enter a word to find similar words: \").strip().lower()\n",
    "\n",
    "if user_word in word2id:\n",
    "    # Calculate distance/similarity\n",
    "    distance_matrix = euclidean_distances(weights)\n",
    "    similar = [id2word[idx] for idx in distance_matrix[word2id[user_word]-1].argsort()[1:6]+1]\n",
    "    print(f\"Top similar words to '{user_word}': {similar}\")\n",
    "else:\n",
    "    print(f\"'{user_word}' not found in vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd04925-8f56-4a53-82cf-cf935bdf7a55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
